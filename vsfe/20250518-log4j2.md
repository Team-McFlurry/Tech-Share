# Bulk/Schedule 을 지원하는 Custom Log4j2 Appender 개발기

## 문제 상황 살펴보기

저희 부서는 장기적인 개발 과제로 전반적인 구조를 개선하고, 데이터의 흐름이 한방향으로 향할 수 있도록 구조를 개선하는 작업을 진행하고 있습니다. 여기에 더해, 다소 히스토리가 오래된 컴포넌트들을 정리하는 작업도 병행하고 있습니다. 이 과정에서, 이번 문제가 발생된 원인이 되었던 특정 개선사항을 **시간 순으로** 살펴보겠습니다.

- 과업로그 저장소를 HDFS에서 Elasticsearch 로 변경
  - 기존에는 HDFS에 과업로그를 전송할 수 있도록 서버 -> Apache Flume -> HDFS로 로그를 전송하도록 개발이 되어 있었는데, Elasticsearch 에 로그를 전송할 수 있도록 Flume을 제외하고, Logstash로 로그를 대체해야 했습니다. 다만 Flume의 역할이 다소 많아 Logstash 로의 완벽한 대체가 불가능했기에, **서버 -> Apache Flume -> Logstash -> Elasticsearch** 로의 로그 전송 파이프라인이 구축되었습니다.
- 후처리 작업의 구조적 통합 수행
  - 원래 과업마다 `@Async`를 통해 후처리 작업들을 수행하도록 개발이 되어 있었는데, 사실 이 부분은 문제가 많았습니다. 서버마다 중복된 코드가 발생하기도 하고, 각 과업마다의 후처리 로직이 아주 약간씩 다르다보니 구조적인 흐름을 판단하기 매우 어려웠습니다.
  - 따라서, 과업 수행 종료 시 **후처리 로직의 실행 타이밍**에 따라 바로 실행되어야 하는 작업들은 각 서버에서, **다소 실행이 지연되어도 되는 것들**은 Kafka 메시지를 발행하여 별도의 컴포넌트에서 로직의 공통화를 수행하도록 했습니다.
  - 이 과정에서, **모든 과업로그는 하나의 컴포넌트**에서 발송하도록 변경되었습니다.
- 특정 클라이언트의 신규 API 전환
  - 부서의 서버 API는 구 API (C++ 기반), 신규 API (Java 기반) 으로 구성되어 있었고, 웹 및 앱은 신규 서버로 전환되었으나 PC 클라이언트는 여전히 구 API를 바라보고 있었습니다.
  - 이후, 마지막으로 남아 있던 **PC 기반 클라이언트까지 신규 서버로 전환되었습니다.**

분명 순차적으로 컴포넌트들이 개선되는 작업이지만, 마지막 작업이 수행된 이후 일이 터지고 맙니다. 초당 전송되는 로그의 TPS가 Peak Time 기준 **5~600TPS** 까지 치솟았고, 이내 과업로그 축적이 지연되더니 결국 로그가 손실되는 문제까지 발생하고 맙니다. 원인을 알아내기 위해 다양한 예측을 했지만, 결론은 다음과 같았습니다.

- **Logstash는 Flume** 을 정식으로 지원하지 않아, HTTP Sink 를 통해 데이터를 전송해야 합니다.
  - 기존 Flume -> HDFS 파이프라인에서는 Bulk 전송이 가능했지만, HTTP Sink 는 구조적으로 Bulk 전송이 불가능합니다.
- Flume은 Queue가 존재하므로 데이터의 유실이나, 로그 전송 실패에 대해 대비가 가능했지만, **트래픽이 몰리자 Queue의 크기를 초과하여 로그가 유실되는 문제** 가 발생했던 것 이었습니다.

그렇다고 유실 없이 로그를 전송하는 방법이 무엇일까요? 당연히 여러분들은 쉽게 떠올리겠지만, fileBeat 등의 도구를 사용하면 될 겁니다. 자연스럽게 저도 해당 도구를 사용하여 파이프라인을 개선할 것을 제안했죠. 하지만 거절 당했습니다.

> 우리는 Container, VM이 혼합되어 운영하고 있는데, 두 환경에서 운용방법이 **달라진다면,** 완전히 전환이 끝나기 전까지는 사용하지 않는게 좋을 것 같다.

네... 뭐... 그렇게 되었습니다. 스크립트 등으로 모든 도구의 lifecycle을 관리하다보니, 이런 관점에서 관리 부담을 언급하시다보니, 결국 **fileBeat를 사용하지 않고, 지연없는 로그 전송을 수행** 해야 하는 상황이 온 것이죠.

## log4j2는 logstash 를 지원하지 않나요?

결론만 말하면, 네.

정확히는 logstash 측에서 지원을 끊었다고 말하는게 좀 더 나을 것 같습니다. log4j 취약점 사태 이후로, 완전히 deprecated 시켰거든요. 그 이후로 log4j2 appender는 나오지도 않았습니다.

> This plugin is deprecated. It is recommended that you use filebeat to collect logs from log4j.

결국, 이전 Apache Flume 의 상황처럼 HTTP Socket 으로 데이터를 보내되, **이를 Bulk 로 보낼** 방법을 찾아야 하는 것이죠.

## Logstash Bulk 설정

사실 이건 쉽습니다. input codec을 line으로 받게되면, **multiline 으로 데이터를 보낼 때, 각각의 line을 하나의 독립된 로그로 간주하기 때문에**, 로그 전송 시 묶어서 로그를 보낼 수 있게 됩니다.

```logstash
input {
        http {
                codec => plain
                port => 8080
                host => "0.0.0.0"
        }

        http {
                codec => line
                port => 8088
                host => "0.0.0.0"
        }
}
```

과업로그의 특성상 **절대로** 라인 구분자가 발생할 수 없으므로, 충분히 수행 가능한 전략이었습니다. 즉, 이제 남은건 과업로그를 전송할 때, 묶어서 전송할 수 있도록 유도하는 것 뿐입니다.

## Log4j2 Appender 이해하기

모든 Appender의 코드를 포함하지 않겠지만, Appender를 개발하면서 다소 중요했던 몇몇 이슈에 대해 다루고자 합니다.

우선, Log4j2의 Appender를 개발하기 위해선 `AbstractAppender`를 상속해야 하는데, 이 과정에서 구현해야 하는 메서드는 다음과 같습니다.

- `void start()`: Appender를 start 합니다. (log4j2에 등록 시, 자동으로 bootup 단계에서 호출됩니다.)
- `void stop()`: Appender를 stop 합니다. (log4j2에 등록 시, 자동으로 shutdown 단계에서 호출됩니다.)
- `void append(LogEvent event)`: LogEvent 를 활용하여, 로그를 전송합니다.

한가지 궁금증이 생길 수 있을텐데, **Spring Bean 과 비교하여, 이 Appender의 생명주기는 어떤가?** 라고 생각할 수 있을 것 입니다. 사실 이는, 중요한 이슈입니다. 만약 Appender의 `stop()` 이 Spring Bean 의 shutdown 이전에 수행된다면, 로그가 손실될 수 있기에 이를 보완하기 위한 완충작업이 필요하거든요. (Graceful Shutdown 을 위한 작업을 수행한다거나...)

결론만 말하면, **spring-log4j2 라이브러리 등으로 Spring 과의 연관관계를 지정했다면, 로깅 라이브러리의 startup은 가장 먼저, stop은 가장 늦게 호출되도록 잡혀있다** 고 할 수 있습니다.

- JVM SIGTERM/System.exit() 발생
- SpringApplicationShutdownHook 내부적으로 ApplicationContext.close() 호출 시, `ContextClosedEvent` 전파
- `ContextClosedEvent` 는 일반적으로 Shutdown Hook 을 수행하기에 이 과정에서 Spring 의 Bean 들이 정리됨 (LoggingSystem 의 경우, 아무것도 하지 않음)
- 마지막으로 JVM Shutdown Hook 에서 등록된 Handler 를 역순으로 실행하면서, 최후의 최후 시점에 로깅 shutdownHandler 가 수행

따라서, 우리는 Log4j2를 사용하고 있다면 이 부분에 대해선 걱정할 필요가 없는 것이죠.

### `ScheduledThreadPoolExecutor` 활용하기

개발한 Appender는 다음과 같은 케이스에 로그 전송을 수행합니다.

* 전송할 로그의 개수가 `batchSize` 이상인 경우
* `flushIntervalSeconds` 초가 지난 경우

Spring 을 사용한다면 `@Scheduled` 에 익숙하겠지만, 저희가 개발하는 Appender는 `@Scheduled` 를 사용하지 않고, Java가 제공하는 스케쥴링을 지원하는 또 다른 해결책을 찾아야 합니다. 그리고 그것이 바로 `ScheduledThreadPoolExecutor` 죠. (`@Scheduled` 는 내부적으로 ``ScheduledThreadPoolExecutor`를 활용하고 있기도 하고요.)

간단하게 설명하자면, `ScheduledThreadPoolExecutor`를 사용하게 되면, 주기적인 스케쥴링 잡을 별도의 스레드풀로 관리할 수 있습니다. 중요한 점이라면, **스레드풀** 인 만큼, 메인 스레드와 별도의 스레드로 관리가 된다는 점 입니다. 다만 저희는 스레드풀을 병렬 목적으로 사용하는 것이 아닌, 스케쥴링 목적으로 사용한다는 점 입니다. 따라서, `this.scheduler = new ScheduledThreadPoolExecutor(1);` 를 통해 스레드를 단 1개만 사용하도록 유도했습니다.

다만, `ScheduledThreadPoolExecutor` 는 `ThreadPoolExecutor` 를 상속하고 있는 만큼, **Delay 없이 바로 실행되는 작업 또한 실행시킬 수 있습니다.** (이 경우, Delay=0 인 Job으로 간주합니다.)

결국,

- Queue에 담긴 데이터의 크기가 `batchSize` 를 도달한 경우, `SchduledThreadPoolExecutor::execute` 를 수행하도록 하여, Queue를 강제로 비웁니다.
- `flushIntervalSeconds` 는 `SchduledThreadPoolExecutor::scheduleAtFixedRate` 로 지정하여, 주기적으로 수행하도록 유도합니다.

## 재전송 처리하기

개발한 Appender는 내부에 HttpAppender를 담고 있습니다. 다만, Log4j2의 특성상, **재전송을 지원하지 않습니다.** 다만, Http 의 특성상 순간적인 네트워크 이슈등을 방지할 필요가 있었고, 이에 재전송 로직을 추가하고자 했습니다.

하지만 httpAppender는 **로그 전송 실패**를 예외로 반환하지 않습니다. 로그 전송을 실패했다는 로그를 남길 뿐이죠.

```java
@Override
public void append(final LogEvent event) {
    try {
        manager.send(getLayout(), event);
    } catch (final Exception e) {
        error("Unable to send HTTP in appender [" + getName() + "]", event, e);
    }
}
```

결국, 저희는 내부의 `manager`를 꺼내서 직접적으로 로그를 전송하도록 유도해야, 예외를 감지하여 재전송을 수행할 수 있도록 만들 수 있겠죠.

다만, 직접 HttpManager (`manager` 의 타입) 을 만들기엔, 해당 객체를 소유하고 있는  HttpAppender 자체의 설정값도 필요했기에, 결국 직접 꺼내서 사용하도록 유도했습니다.

```Java
/**
 * HttpAppender에 LogEvent를 append 한다.
 * - HttpAppender.append() 의 경우 실패 시 재처리 로직이 존재하지 않으므로, 직접 내부 HttpMananger에 추가를 시도함.
 * @param event
 */
private void appendToHttpAppender(@NotNull LogEvent event) {
    try {
        var managerField = HttpAppender.class.getDeclaredField("manager");
        managerField.setAccessible(true); // NOSONAR
        var httpManager = (HttpManager)managerField.get(baseHttpAppender);

        sendToHttpManager(httpManager, event);
    } catch (Exception e) {
        LOGGER.error("Unable to process HttpManager", e);
    }
}

/**
 * HttpManager에 LogEvent를 전송한다. (retry 포함)
 * 실패 시 RETRY_PERIOD 만큼 대기 후 재시도 (로그 전송 작업은 별도의 스레드에서 수행 되므로, 서비스 로직 영향은 최소화)
 * @param httpManager
 * @param event
 */
private void sendToHttpManager(@NotNull HttpManager httpManager, @NotNull LogEvent event) throws Exception {
    for (var i = 0; i < RETRY_COUNT; i++) {
        try {
            httpManager.send(baseHttpAppender.getLayout(), event);
            return;
        } catch (Exception e) {
            LOGGER.error("Failed to send log event to HttpManager, attempt {} of {}", i + 1, RETRY_COUNT, e);
            Thread.sleep(RETRY_PERIOD);
        }
    }

    LOGGER.error("Failed to send log event to HttpManager after {} attempts, event - {}", RETRY_COUNT, event);
}
```

## 번외 - 발생할 뻔한 Blocking 이슈, 그리고 성능 뽑아내기

(*주의: 여기는 다소 난이도가 높은 내용이 포함되어 있습니다.)

처음 구현한 `append()` 의 구현은 다음과 같습니다.

```Java
/**
 * LogEvent 를 Queue에 append 한다.
 * (참고: 해당 logger의 목적상, LogEvent 의 Level은 로깅 대상에서 제외된다.)
 * @param event
 */
@Override
public void append(@NotNull LogEvent event) {
    if (shutdownInitiated.get()) {
        return;
    }

    if (!queue.offer(event.toImmutable())) {
        LOGGER.warn("HttpBulkAppender: Queue is full. Skipping append. name: {}, Event: {}", super.getName(), event);
    }

    if (queue.size() >= batchSize) {
        flushQueue();
    }
}

/**
 * Queue에 있는 LogEvent를 flush 하여, Logstash에 전송한다.
 */
private synchronized void flushQueue() {
    List<LogEvent> events = new LinkedList<>();
    queue.drainTo(events);
    
    if (!events.isEmpty()) {
        sendBulkEvents(events);
    }
}
```

이 코드의 문제가 무엇인지 보이나요?

바로 **Application Thread가 flush 를 실행하는 주체가 된다는 점** 입니다. 일반적인 케이스에는 문제가 없지만, 네트워크 이슈 등으로 인해 로그 전송이 지연된다면, Application Thread가 Blocking 될 위험이 존재한다는 것 입니다.

성능 테스트 관점에서는 발생하지 않았기에 해당 문제를 그대로 넘길 뻔 했으나, 마지막 코드를 리뷰하는 과정에서 우연히 발견했었습니다.

사실 이참에 네트워크 딜레이 이슈에 대해 조금 더 고민해보니, **결국 네트워크 딜레이에 의해 로그 전송 지연이 발생하면, `flushIntervalSeconds`을 엄격하게 지킬 수 없는 것 아닌가?** 라는 생각이 들었습니다. (추가적으로, 로그가 쌓이게 되어 `batchSize` 에 도달한다고 해도, TheadPoolSize 가 1인 만큼 로그 전송이 불가능하겠죠.)

이참에 성능을 최대한으로 개선하기 위해, 다음과 같은 해결책을 내놓았습니다.

>- Application Thread 는 데이터를 Queue에 넣는 역할만 하고, 절대로 flush 를 수행하지 않음.
>- Lock 경합을 최소화 하기 위해, queueSize를 확인하기 위해 `LinkedBlockingQueue.size()`를 호출하지 않고, `AtomicInteger` 로 별도 길이 카운트 (`LinkedBlockingQueue` 는 내부적으로 `size()` 호출을 위해 진입 시점에 락을 획득하기 때문에, 성능 개선을 위해 atomic 하게 변경함.)
>- `batchSize` 에 도달할 경우, flag 를 true로 돌리고, (이 때, CAS를 통해 flush 1회만 실행되도록 함.) schduledThreadPool 에 interval = 0 으로 flush 를 수행하도록 함. (execute 메서드의 구현체를 보면, interval을 0L로 넣도록 구현되어 있습니다.)
>- Time Interval 로 인한 flush 작업 중 네트워크 딜레이 등으로 지연되는 상황이 발생할 경우를 방지하기 위해, ThreadPool의 `PoolSize`를 2로 설정했습니다. (어떠한 상황에서도 batchSize에 의한 flush 가 수행될 수 있도록)
>
>(실제 PR 리뷰 코멘트)

다만, 이렇게 작업하니 다른 분들도 코드 이해를 못하는 (...) 상황에 놓였고, 해당 솔루션은 지연되는 상황이 실제로 발생할 시, 로그 지연 추이를 보고 도입 여부를 결정하기로 했습니다.

```Java
private final AtomicInteger currentSize = new AtomicInteger();
private final AtomicBoolean flushRequested = new AtomicBoolean(false);
private final AtomicBoolean shutdownInitiated = new AtomicBoolean(false);

// 생성자
public HttpBulkAppender(String name, Filter filter, AppenderRef[] appenderRefs,
		Configuration configuration, int batchSize, int flushIntervalSeconds) {
    // 중략
    // Scheduled Flush 수행 지연 시, BatchSize 로 인한 즉시 Flush 를 병행할 수 있도록, Thread 수 2개로 설정
    this.scheduler = Executors.newScheduledThreadPool(2, r -> {
        var t = new Thread(r, SCHEDULED_THREAD_NAME);
        t.setDaemon(true);
        return t;
    });
}

@Override
public void append(@NotNull LogEvent event) {
    if (shutdownInitiated.get()) {
        return;
    }

    if (!queue.offer(event.toImmutable())) {
        LOGGER.warn("HttpBulkAppender: Queue is full. Skipping append. name: {}, Event: {}", super.getName(), event);
    }

    int size = currentSize.incrementAndGet();
    if (size >= batchSize && flushRequested.compareAndSet(false, true)) {
        scheduler.execute(this::flushQueue);
    }
}


/**
 * Queue에 있는 LogEvent를 flush 하여, Logstash에 전송한다.
 */
private synchronized void flushQueue() {
    List<LogEvent> events = new LinkedList<>();
    queue.drainTo(events);

    if (!events.isEmpty()) {
        sendBulkEvents(events);
    }

    currentSize.addAndGet(-events.size());
    flushRequested.set(false);
}
```



## 총평

다소 반신반의한 시도였지만, 결과는 좋았습니다. 기본적으로 하나의 서버에 1000 TPS 정도의 부하를 3시간째 가했음에도 안정적으로 로그 전송이 가능했으며, 기본적으로 Kafka Consumer 컴포넌트를 4~8대 운용하고 있으므로, 수용 가능한 로그의 양은 그에 비례해 늘어난다고 할 수 있죠.

해당 Log Appender 배포 이후로 과업로그의 지연 전송 및 손실이 0으로 줄어들었으며, 현재까지도 안정적으로 운용중에 있습니다.