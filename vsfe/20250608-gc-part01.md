# Java의 GC는 웹서비스에 어떤 영향을 미치는가? (Part 1)
> 해당 글은 완성된 내용은 아닙니다. 다만 발표 시간 동안 모든 내용을 담기에는 상당히 양이 많아, 적당히 압축하여 다룹니다.
> 

> 참고: 이 글은 JVM의 GC 알고리즘에 대한 이해가 되어 있다는 전제하에 작성된 글 입니다.
GC 알고리즘에 대해 이 글에서 다루지 않습니다.
>

Java를 공부하다보면 필연적으로 나오는 것이 바로 GC (Garbage Collector) 이다. GC 덕분에 메모리 관리를 명시적으로 할 필요는 없지만, 어느 순간 발생할 수 밖에 없는 STW (Stop-The-World) 로 인해 여러 문제가 유발될 수 있다는 양날의 검 역할을 한다.

... 까지가 우리가 Java를 공부하면 볼 수 있는 내용인데, *우리가 과연 웹서비스를 개발하는 과정에서 GC를 고려하고 개발하였나?* 라고 한다면 사실 그렇지 않은 사람이 더 많을 것이다. 애초에 웹서비스엔 정말로 GC가 중요한 것일까?

GC가 발생했을 때 웹서비스 관점에서 어떤 일이 발생하고 어떤 영향을 미치는지, 얼마나 자주 발생하는지, 어떤 것을 고민해야 할지 생각해보는 시간을 갖도록 하자.

## STW 때 무슨 일이 일어나는가?

우선, 이를 다루기 위해선 **JVM Safepoint** 라는 용어를 언급해야 한다. 이는 스레드가 *멈춰도 된다* 라고 JVM에 약속한 지점을 의미한다. 조금 긴가민가할 수 있는 개념인데, 간단히 말해서 **모든 JVM의 스레드가 메모리 구조를 변경하지 않도록 특정 지점까지 수행하게 유도** 하도록 하는 것이다.

특히나 STW 상황이 발생했을 때는 메모리 전체를 스캔하는 과정이 필요한데, 이때 스레드의 객체 동시 참조를 없애 안전하게 스캔을 하기 위한 의도가 있다고 볼 수 있다.

(참고로, 단순히 STW 뿐만 아니라, 디버깅 수행 및 JIT deoptimization 등의 작업을 수행할 때도 JVM Safepoint 개념을 활용한다.)

한가지 더 언급하자면, **네트워크 스택**은 JVM 바깥의 OS 영역이기 때문에, STW의 영향을 받지 않는다는 것도 인지해야 한다. 즉, 웹서비스의 기본이 되는 WAS 자체는 STW의 영향을 강하게 받지만, 네트워크 스택은 그렇지 않으므로, 이로 인해 발생하는 차이를 인지해야 한다.

### Tomcat

- JVM Safepoint 관점에선, Tomcat에 속하는 모든 Worker, Acceptor, Polling 스레드가 전부 Safepoint 에 진입할 것이다.
- Acceptor가 멈추다보니, TCP 관점에서 **SYN -> ESTABLISHED** 전환이 불가능해지고, 그에 따라 요청이 OS의 **Backlog Queue**에 쌓이게 된다.
    - Tomcat의 경우, 기본적으로 요청을 받아들이기 위해 NIO/NIO2 를 사용하는데, C 라이브러리인 libc의 accept 호출 이후 바로 주도권이 Java로 넘어가는 문제도 존재한다.
- 즉, STW가 길어지거나 순간적으로 엄청난 양의 요청이 몰린다면, 큐가 가득차게 될 것이고 결국 커널은 새 요청을 받아들이지 못할 것이다.
- 또한, 이미 ESTABLISHED 된 연결이라고 해도, `Socket::read()` 가 막히게 되므로 TCP의 수신 버퍼가 가득차게 될 위험이 있다.

### OS Kernel

#### 이미 열린 Keep-Alive 연결

- 클라이언트에서 서버로 데이터 전송 시, TCP Segment 는 OS 내부의 소켓 수신 버퍼에 적재된다.
- Tomcat은 `Socket::read()` 를 수행해야 커널의 버퍼를 읽을 수 있는데, STW로 인해 데이터를 읽지 못하므로 버퍼는 지속적으로 찰 수 밖에 없다.

#### 새로운 TCP 연결

- 커널은 SYN-ACK 까지는 수행해주나, `accept()`는 Java 의 영역으로 넘어가기 때문에 온전한 **ESTABLISHED** 상태로 전환이 불가능해진다.
- 결국 이 과정에서 상술한 것 처럼 backlog가 차게 된다.

#### HTTP3 라면...?

- 사실 UDP는 비연결성이므로, 커널 버퍼에 데이터를 그대로 적재할 뿐이다.
- 다만 어쨌거나 들어오는 요청을 읽고 처리할 수 없으므로, 오버플로우 발생 시 드랍되는 것은 변함 없다.

### STW가 길어지면 어떻게 될까?

요즘 GC 알고리즘의 발전으로 STW가 많이 짧아졌다는 이야기는 들었을 것이다. 그렇다면, 웹서비스 관점에서 STW는 얼마나 짧아져야 할까? 사실 이건 어렵지 않은 질문이긴 하다. 서버의 응답이 얼마나 길게 끊기는지 생각하면 되기 때문이다.

| STW 길이     | 증상                                                         |
| ------------ | ------------------------------------------------------------ |
| < 10 ms      | 대부분 무시 가능한 레이턴시 스파이크                         |
| 수십 ms      | APM trace에서 인지 가능, P99 지연 증가                       |
| 100 ms – 1 s | 브라우저·L4 LB에서 **HTTP 요청 타임아웃/502** 스파이크, gRPC keep-alive ping 지연 |
| > 1 s        | TCP 재전송 급증, AWS/Nginx health-check failure, Circuit-Breaker open, Kafka producer timeout 등 |

상술 했듯이, 네트워크 스택은 커널이 담당하고 있으므로, 결국 backlog와 로드 밸런서의 설정만 잘 조정한다면, 어느정도의 STW는 단순 응답 지연으로 끝낼 수 있을 것이다. (문제는, 규모 있는 서비스라면 그것도 한계가 있기 때문에 결국은 GC 알고리즘에 대해 관심을 가질 수 밖에 없다.)

## 웹서비스에서, GC는 얼마나 자주 발생하는가?

### 일반적인 REST API 관점에서

간혹 사람들이 **REST API는 다양한 API가 있고, 많은 DTO 들이 생성되니, GC가 자주 발생하지 않나?** 라고 생각하는 경우가 있다. 하지만 보통 DTO는 매우 짧게 생성되고 참조 해제가 이루어지기 때문에, 결과적으로 Minor GC 의 영역에서 처리가 이뤄진다.

결국 문제는, **어떻게든 살아있는 객체가 있다면** 발생하는 것인데, 웹서비스에선 어떤 것들에 의해 이러한 문제가 발생할 수 있을까?

#### 네트워크 문제

- Keep-Alive 소켓은 Tomcat의 `Http11NioProcessor` 로 관리된다. 이 객체는 연결이 오래 살아있다면 버퍼나 파이프라인, TLS Context가 계속하여 참조될 수 있고, 이로 인해 Old 영역에 객체가 축적되어 Full GC의 대상이 될 수 있다.

#### Minor GC가 여러번 발생했음에도 살아있는 죽은 객체들

어찌보면 이 문제가 제일 자주 발생하는 문제라고 생각한다. 우선, Generation GC 관점에서 Minor GC를 몇 번 버티면 Old 영역으로 간다는 것을 기억하자.

- 트래픽이 몰리게 되면, Eden 영역이 가득차게 될 것이고 이 과정에서 Minor GC가 수행되기 전에도 **Survivor 공간이 부족해지는** 상황이 올 수 있다. 이렇게 될 경우 살아남은 객체를 그대로 Old 영역에 밀어넣게 되고, 결국 운이 나쁘면 엄청난 양의 DTO가 Old 영역으로 넘어갈 수 있다.
- 구형 GC를 사용할 경우 이 문제가 더욱 크게 두드러지는데, 상황에 따라 **Old 영역에 보내지 않고도 힙이 찼다면 그냥 Full GC를 트리거링 할 수 있다.** 그 상황이 지속적으로 반복된다면 트래픽이 늘어날 수록 성능 악영향은 더욱 커질 것이다.

#### 장기 작업 처리로 인한 Reference

- 비동기 작업으로 처리되는 경우, 작업 시간에 대해서 관심을 안 갖는 경우가 많은데, 이게 오히려 독이 되는 경우다.
- 비동기 로깅이나, rxJava/Reactor의 `publishOn`, ThreadLocal 캐시, MQ BackPressure, Local Cache 등으로 인해 특정 객체가 오랫동안 JVM 메모리에 남는 경우, Minor GC 시점에는 객체가 지워지지 않을 것이고, 결국 Full GC의 영역으로 넘어가게 될 것이다.

#### Humongous 객체

- 객체의 크기가 너무 크면, 절대 Eden 영역에 남지 않는다.
- G1을 기준으로 설명하면, >= 128 KB 객체를 Old 영역에 바로 보내고, `StringBuilder` 는 113KB 이상의 크기를 갖는 경우 Old 영역으로 보낸다.
- 만약 파일 등을 `byte[]` 등으로 버퍼링 할 경우, 문제가 될 수 있다.
    - 잠깐, 여기서 `MultipartFile` 은 어떨까?
    - 놀랍게도, 해당 객체 자체는 매우 작은 객체이므로, Humongous 하지 않다.
    - 내용물은 구현체에 따라 약간 다르지만, **파일을 직접적으로 꺼내오지 않는 이상, Humongous 정책에서 다소 자유롭다**
        - 대표적인 구현체인 `StandardMultipartFile` (Spring MVC 구현체로, Servlet 기반) 은 Tomcat의 `fileSizeThreshold` 정책의 영향을 받으며, 이를 초과하면 디스크에 파일을 작성하여 이 문제를 회피한다.
        - 비슷한 Apache Commons의 `CommonsMultipartResolver` 는 특정 파라미터의 영향을 받고, 구현의 차이는 있지만 (`DiskFileItem` 이라는 객체를 참조함) 디스크에 쓰여지는 것은 동일하다.
    - 결국, `MultipartFile` 을 Stream 으로 읽게 되면 이 문제는 발생하지 않는다.

#### 라이브러리 내 자체 캐싱 로직으로 인한 문제

위에서 언급한 장기 작업과 유사한 문제라고 할 수 있다.

- 단순 캐시를 목적으로 데이터를 저장하는 경우, 캐시 풀이 잘 관리되지 않거나 적재 시간이 너무 길어 Old 영역으로 올라가는 경우가 상당히 많다.
    - 라이브러리들 중에선, 최신 버전에서 이런 캐시들을 `WeakReference`로 대체해서 사용하는 경우가 많은데, WeakReference를 사용하면 LRU 캐시 등을 구현하는 과정에서 효율성을 높일 수 있다.
    - 참고: https://d2.naver.com/helloworld/329631

#### Tomcat의 안전장치?

- 사실 메모리가 꽉차지 않아도 Major GC가 발생하는 경우가 존재한다. 이는, 애플리케이션에서 `System.gc()` 를 호출하는 경우인데, 일반적인 경우엔 절!대! 이걸 호출할 일은 없다.
    - 하지만 Tomcat은 이걸 호출한다 (???)
    - Tomcat은 JreMemoryLeak 방지를 위해 1시간 마다 정기적으로 GC가 발생한다. (참고: https://github.com/apache/tomcat/blob/main/java/org/apache/catalina/core/JreMemoryLeakPreventionListener.java)
    - 이를 방지하기 위해선 tomcat 설정에서 해당 리스너를 꺼버리면 되지만, 의도가 의도인 만큼 튜닝을 하는 상황이 아니라면 그냥 두는게 낫긴 할 것이다.

### 2부에선?

2부에선, 좀 더 심화적인 내용을 기반으로 GC를 활용하기 위한 방법과, 최신 GC 알고리즘를 웹서비스 관점에서 설명해 보려고 한다.

- JVM은 GC와 관련한 정말 수많은 설정값을 제공하고 있다. 이 설정값들을 어떻게 작성하냐에 따라 상당한 수준의 성능 차이를 보여준다. 모든 파라미터를 전부 활용하는 것은 불가능하지만, 적극적으로 활용해 볼만한 파라미터들을 살펴보자.

- 사실 지금까지는 은연중에 **Generation GC 계열** 을 상정하고 언급하다보니, 최신 GC 알고리즘에 대해서는 집중적으로 다루지 않았다.(ZGC, Shenandoah 등...) 해당 알고리즘은 STW를 최소화 하기 위해 다양한 노력을 했으나, **결국 이 친구들도 상황에 따라 Full GC가 발생** 이 가능하므로, 결국 이를 근본적으로 해결하지 않으면  안전하다고 할 수 없다. 과연 트래픽이 몰리는 웹서비스에서는 이 알고리즘들이 어떤 영향을 줄까?



